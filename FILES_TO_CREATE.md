# ìƒì„±í•  íŒŒì¼ ëª©ë¡ ë° ë‚´ìš©

## ë””ë ‰í† ë¦¬ êµ¬ì¡°

```
ax-advanced-mini-prj/
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ .env.example
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â”œâ”€â”€ SETUP_PLAN.md (âœ“ ì´ë¯¸ ìƒì„±ë¨)
â”œâ”€â”€ ARCHITECTURE.md (âœ“ ì´ë¯¸ ìƒì„±ë¨)
â”œâ”€â”€ FILES_TO_CREATE.md (ì´ íŒŒì¼)
â”‚
â”œâ”€â”€ src/
â”‚   â””â”€â”€ ai_assistant/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ config.py
â”‚       â”œâ”€â”€ agent.py
â”‚       â”œâ”€â”€ tools.py
â”‚       â”œâ”€â”€ prompts.py
â”‚       â””â”€â”€ utils.py
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ test_agent.py
â”‚
â””â”€â”€ examples/
    â”œâ”€â”€ basic_chat.py
    â””â”€â”€ code_generation.py
```

---

## 1. pyproject.toml

```toml
[project]
name = "ai-coding-assistant"
version = "0.1.0"
description = "AI Coding Assistant using LangChain and LangGraph with OpenRouter"
readme = "README.md"
requires-python = ">=3.11"
authors = [
    {name = "Your Name", email = "your.email@example.com"}
]
dependencies = [
    "langchain>=0.3.0",
    "langchain-openai>=0.2.0",
    "langgraph>=0.2.0",
    "langchain-community>=0.3.0",
    "langchain-core>=0.3.0",
    "python-dotenv>=1.0.0",
    "httpx>=0.27.0",
    "pydantic>=2.0.0",
]

[project.optional-dependencies]
dev = [
    "pytest>=8.0.0",
    "pytest-asyncio>=0.24.0",
    "black>=24.0.0",
    "ruff>=0.6.0",
    "mypy>=1.11.0",
    "ipython>=8.20.0",
]

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.black]
line-length = 100
target-version = ["py311"]
exclude = '''
/(
    \.git
  | \.venv
  | __pycache__
  | build
  | dist
)/
'''

[tool.ruff]
line-length = 100
target-version = "py311"
select = ["E", "F", "I", "N", "W"]
ignore = ["E501"]

[tool.mypy]
python_version = "3.11"
warn_return_any = true
warn_unused_configs = true
disallow_untyped_defs = false
ignore_missing_imports = true

[tool.pytest.ini_options]
testpaths = ["tests"]
python_files = "test_*.py"
python_classes = "Test*"
python_functions = "test_*"
asyncio_mode = "auto"
```

---

## 2. .env.example

```env
# OpenRouter API Key (í•„ìˆ˜)
# https://openrouter.ai/keys ì—ì„œ ë°œê¸‰ë°›ìœ¼ì„¸ìš”
OPENROUTER_API_KEY=your_openrouter_api_key_here

# OpenRouter Model (ì„ íƒì‚¬í•­)
# ì¶”ì²œ: anthropic/claude-3.5-sonnet
# ê¸°íƒ€: openai/gpt-4-turbo, google/gemini-pro-1.5, meta-llama/llama-3.1-70b-instruct
OPENROUTER_MODEL=anthropic/claude-3.5-sonnet

# LangSmith ì„¤ì • (ì„ íƒì‚¬í•­ - ë””ë²„ê¹… ë° íŠ¸ë ˆì´ì‹±ìš©)
LANGCHAIN_TRACING_V2=false
LANGCHAIN_API_KEY=your_langsmith_api_key_here
LANGCHAIN_PROJECT=ai-coding-assistant
LANGCHAIN_ENDPOINT=https://api.smith.langchain.com
```

---

## 3. .gitignore

```gitignore
# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python

# Distribution / packaging
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
share/python-wheels/
*.egg-info/
.installed.cfg
*.egg
MANIFEST

# Virtual Environment
.venv/
venv/
ENV/
env/
.virtualenv/

# IDE
.vscode/
.idea/
*.swp
*.swo
*~
.DS_Store

# Environment variables
.env
.env.local

# UV
uv.lock
.uv/

# Testing
.pytest_cache/
.coverage
.coverage.*
htmlcov/
.tox/
.nox/

# Type checking
.mypy_cache/
.dmypy.json
dmypy.json
.pytype/

# Jupyter Notebook
.ipynb_checkpoints
*.ipynb

# Logs
*.log
logs/

# Database
*.db
*.sqlite
*.sqlite3

# Cache
.cache/
*.cache
```

---

## 4. README.md

```markdown
# AI Coding Assistant

LangChainê³¼ LangGraphë¥¼ í™œìš©í•œ AI ì½”ë”© ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. OpenRouterë¥¼ í†µí•´ ë‹¤ì–‘í•œ LLM ëª¨ë¸ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

## ì£¼ìš” ê¸°ëŠ¥

- ğŸ¤– **ì½”ë“œ ìƒì„±**: ìì—°ì–´ ì„¤ëª…ìœ¼ë¡œ ì½”ë“œ ìƒì„±
- ğŸ“– **ì½”ë“œ ì„¤ëª…**: ë³µì¡í•œ ì½”ë“œë¥¼ ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…
- ğŸ”„ **ëŒ€í™”í˜• ì¸í„°í˜ì´ìŠ¤**: ì§€ì†ì ì¸ ì»¨í…ìŠ¤íŠ¸ ìœ ì§€
- ğŸ› ï¸ **í™•ì¥ ê°€ëŠ¥**: ìƒˆë¡œìš´ ë„êµ¬ ì‰½ê²Œ ì¶”ê°€ ê°€ëŠ¥

## ê¸°ìˆ  ìŠ¤íƒ

- **LangChain**: LLM ì• í”Œë¦¬ì¼€ì´ì…˜ í”„ë ˆì„ì›Œí¬
- **LangGraph**: ìƒíƒœ ê¸°ë°˜ ì—ì´ì „íŠ¸ ì›Œí¬í”Œë¡œìš°
- **OpenRouter**: ë©€í‹° LLM í”„ë¡œë°”ì´ë”
- **UV**: ë¹ ë¥¸ Python íŒ¨í‚¤ì§€ ê´€ë¦¬

## ë¹ ë¥¸ ì‹œì‘

### 1. ì‚¬ì „ ìš”êµ¬ì‚¬í•­

- Python 3.11 ì´ìƒ
- UV íŒ¨í‚¤ì§€ ë§¤ë‹ˆì €
- OpenRouter API í‚¤

### 2. UV ì„¤ì¹˜ (Windows PowerShell)

```powershell
irm https://astral.sh/uv/install.ps1 | iex
```

### 3. í”„ë¡œì íŠ¸ ì„¤ì •

```powershell
# ì €ì¥ì†Œ í´ë¡  (ë˜ëŠ” ë””ë ‰í† ë¦¬ë¡œ ì´ë™)
cd ax-advanced-mini-prj

# ê°€ìƒí™˜ê²½ ìƒì„±
uv venv

# ê°€ìƒí™˜ê²½ í™œì„±í™”
.\.venv\Scripts\Activate.ps1

# ì˜ì¡´ì„± ì„¤ì¹˜
uv pip install -e .

# ê°œë°œ ì˜ì¡´ì„± í¬í•¨ ì„¤ì¹˜
uv pip install -e ".[dev]"
```

### 4. í™˜ê²½ ë³€ìˆ˜ ì„¤ì •

```powershell
# .env.exampleì„ .envë¡œ ë³µì‚¬
Copy-Item .env.example .env

# .env íŒŒì¼ í¸ì§‘í•˜ì—¬ API í‚¤ ì…ë ¥
notepad .env
```

`.env` íŒŒì¼ì— OpenRouter API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”:
```env
OPENROUTER_API_KEY=sk-or-v1-...
```

### 5. ì‚¬ìš© ì˜ˆì œ

#### ê¸°ë³¸ ì‚¬ìš©

```python
import asyncio
from ai_assistant.agent import create_agent

async def main():
    agent = create_agent()
    
    response = await agent.ainvoke({
        "messages": [("user", "Write a Python function to calculate fibonacci numbers")]
    })
    
    print(response["messages"][-1].content)

asyncio.run(main())
```

#### CLI ì¸í„°í˜ì´ìŠ¤

```powershell
python examples/basic_chat.py
```

## í”„ë¡œì íŠ¸ êµ¬ì¡°

```
ax-advanced-mini-prj/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ ai_assistant/       # ë©”ì¸ íŒ¨í‚¤ì§€
â”‚       â”œâ”€â”€ agent.py        # LangGraph ì—ì´ì „íŠ¸
â”‚       â”œâ”€â”€ tools.py        # ì½”ë”© ë„êµ¬ë“¤
â”‚       â”œâ”€â”€ prompts.py      # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
â”‚       â”œâ”€â”€ config.py       # ì„¤ì • ê´€ë¦¬
â”‚       â””â”€â”€ utils.py        # ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
â”œâ”€â”€ tests/                  # í…ŒìŠ¤íŠ¸
â”œâ”€â”€ examples/               # ì‚¬ìš© ì˜ˆì œ
â””â”€â”€ docs/                   # ë¬¸ì„œ
```

## ì§€ì› ëª¨ë¸

OpenRouterë¥¼ í†µí•´ ë‹¤ì–‘í•œ ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥:

| ëª¨ë¸ | ìš©ë„ | íŠ¹ì§• |
|------|------|------|
| `anthropic/claude-3.5-sonnet` | ì¶”ì²œ | ìµœê³  í’ˆì§ˆ, ê¸´ ì»¨í…ìŠ¤íŠ¸ |
| `openai/gpt-4-turbo` | ì½”ë“œ ë¦¬ë·° | ë¹ ë¥¸ ì‘ë‹µ |
| `google/gemini-pro-1.5` | ì‹¤í—˜ | ë¬´ë£Œ í‹°ì–´ ê°€ëŠ¥ |
| `meta-llama/llama-3.1-70b` | ë¹„ìš© ì ˆê° | ì €ë ´í•œ ê°€ê²© |

## ê°œë°œ

### í…ŒìŠ¤íŠ¸ ì‹¤í–‰

```powershell
pytest
```

### ì½”ë“œ í¬ë§·íŒ…

```powershell
# Blackìœ¼ë¡œ í¬ë§·íŒ…
black src/ tests/

# Ruffë¡œ ë¦°íŒ…
ruff check src/ tests/

# íƒ€ì… ì²´í¬
mypy src/
```

## ë¬¸ì„œ

- [ì„¤ì • ê°€ì´ë“œ](SETUP_PLAN.md) - ìƒì„¸í•œ ì„¤ì • ë°©ë²•
- [ì•„í‚¤í…ì²˜](ARCHITECTURE.md) - ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜ ì„¤ëª…
- [íŒŒì¼ ìƒì„± ëª©ë¡](FILES_TO_CREATE.md) - ìƒì„±í•  íŒŒì¼ë“¤

## ë¼ì´ì„ ìŠ¤

MIT License

## ê¸°ì—¬

ì´ìŠˆì™€ PRì„ í™˜ì˜í•©ë‹ˆë‹¤!

## ë¬¸ì œ í•´ê²°

### UV ê´€ë ¨ ë¬¸ì œ

```powershell
# UV ì¬ì„¤ì¹˜
irm https://astral.sh/uv/install.ps1 | iex

# ìºì‹œ ì •ë¦¬
uv cache clean
```

### ê°€ìƒí™˜ê²½ í™œì„±í™” ì‹¤íŒ¨

```powershell
# PowerShell ì‹¤í–‰ ì •ì±… ë³€ê²½
Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser
```

### OpenRouter ì—°ê²° ì˜¤ë¥˜

- API í‚¤ í™•ì¸
- ì¸í„°ë„· ì—°ê²° í™•ì¸
- í¬ë ˆë”§ ì”ì•¡ í™•ì¸: https://openrouter.ai/credits

## ì°¸ê³  ìë£Œ

- [LangChain ë¬¸ì„œ](https://python.langchain.com/)
- [LangGraph ë¬¸ì„œ](https://langchain-ai.github.io/langgraph/)
- [OpenRouter ë¬¸ì„œ](https://openrouter.ai/docs)
- [UV ë¬¸ì„œ](https://github.com/astral-sh/uv)
```

---

## 5. src/ai_assistant/__init__.py

```python
"""AI Coding Assistant using LangChain and LangGraph."""

__version__ = "0.1.0"

from .agent import create_agent
from .config import get_config

__all__ = ["create_agent", "get_config"]
```

---

## 6. src/ai_assistant/config.py

```python
"""Configuration management for the AI assistant."""

from typing import Optional
from pydantic import BaseModel, Field
from dotenv import load_dotenv
import os

# Load environment variables
load_dotenv()


class Config(BaseModel):
    """Application configuration."""
    
    openrouter_api_key: str = Field(
        default_factory=lambda: os.getenv("OPENROUTER_API_KEY", "")
    )
    openrouter_model: str = Field(
        default_factory=lambda: os.getenv(
            "OPENROUTER_MODEL", 
            "anthropic/claude-3.5-sonnet"
        )
    )
    temperature: float = Field(default=0.7)
    max_tokens: Optional[int] = Field(default=None)
    
    # LangSmith settings
    langchain_tracing: bool = Field(
        default_factory=lambda: os.getenv("LANGCHAIN_TRACING_V2", "false").lower() == "true"
    )
    langchain_api_key: Optional[str] = Field(
        default_factory=lambda: os.getenv("LANGCHAIN_API_KEY")
    )
    langchain_project: str = Field(
        default_factory=lambda: os.getenv("LANGCHAIN_PROJECT", "ai-coding-assistant")
    )
    
    class Config:
        """Pydantic config."""
        env_file = ".env"
        env_file_encoding = "utf-8"


def get_config() -> Config:
    """Get the application configuration."""
    return Config()


def validate_config(config: Config) -> None:
    """Validate configuration."""
    if not config.openrouter_api_key:
        raise ValueError(
            "OPENROUTER_API_KEY is required. "
            "Please set it in your .env file or environment variables."
        )
```

---

## 7. src/ai_assistant/prompts.py

```python
"""Prompt templates for the AI assistant."""

SYSTEM_PROMPT = """You are an expert coding assistant powered by advanced AI.
Your role is to help developers with:
- Writing clean, efficient code
- Explaining complex code concepts
- Debugging and problem-solving
- Following best practices

Always provide:
1. Clear explanations
2. Well-commented code
3. Error handling
4. Best practices

When generating code:
- Use appropriate design patterns
- Follow language-specific conventions
- Include docstrings/comments
- Consider edge cases
- Add type hints where applicable
"""

CODE_GENERATION_PROMPT = """Generate {language} code for the following task:

{task_description}

Requirements:
- Follow {language} best practices
- Include error handling
- Add clear comments
- Use type hints (if applicable)
- Make the code production-ready

Additional context: {context}
"""

CODE_EXPLANATION_PROMPT = """Explain the following code in {detail_level} detail:

```{language}
{code}
```

Focus on:
- What the code does
- How it works step-by-step
- Key concepts and patterns used
- Potential improvements or issues
"""

GENERAL_CHAT_PROMPT = """You are having a conversation with a developer about coding topics.

Previous context: {context}

Provide helpful, accurate, and concise responses. If asked to write code, 
use the code generation tool. If asked to explain code, use the code explanation tool.
"""
```

---

## 8. src/ai_assistant/tools.py

```python
"""Tools for the AI coding assistant."""

from langchain.tools import tool
from typing import Literal


@tool
def generate_code(
    task_description: str,
    language: str = "python",
    framework: str = None
) -> str:
    """Generate code based on the given task description.
    
    Args:
        task_description: Description of what the code should do
        language: Programming language (default: python)
        framework: Optional framework to use
    
    Returns:
        Generated code as a string
    """
    # This is a placeholder - the actual implementation will be handled by the LLM
    return f"Tool called: generate_code for {language}"


@tool
def explain_code(
    code: str,
    detail_level: Literal["brief", "detailed"] = "brief"
) -> str:
    """Explain the given code.
    
    Args:
        code: The code to explain
        detail_level: Level of detail (brief or detailed)
    
    Returns:
        Explanation of the code
    """
    # This is a placeholder - the actual implementation will be handled by the LLM
    return f"Tool called: explain_code with {detail_level} detail"


def get_tools():
    """Get all available tools."""
    return [generate_code, explain_code]
```

---

## 9. src/ai_assistant/agent.py

```python
"""LangGraph agent for the AI coding assistant."""

from typing import TypedDict, Annotated, Literal
from langchain_openai import ChatOpenAI
from langchain_core.messages import BaseMessage, SystemMessage
from langgraph.graph import StateGraph, END
from langgraph.graph.message import add_messages
from langgraph.prebuilt import ToolNode

from .config import get_config, validate_config
from .tools import get_tools
from .prompts import SYSTEM_PROMPT


class AgentState(TypedDict):
    """State for the agent."""
    messages: Annotated[list[BaseMessage], add_messages]
    context: str
    task_type: Literal["code_generation", "code_explanation", "general_chat"]


def create_llm():
    """Create and configure the LLM."""
    config = get_config()
    validate_config(config)
    
    return ChatOpenAI(
        model=config.openrouter_model,
        openai_api_key=config.openrouter_api_key,
        openai_api_base="https://openrouter.ai/api/v1",
        default_headers={
            "HTTP-Referer": "http://localhost:3000",
            "X-Title": "AI Coding Assistant"
        },
        temperature=config.temperature,
        max_tokens=config.max_tokens,
    )


def should_continue(state: AgentState) -> str:
    """Determine if we should continue or end."""
    messages = state["messages"]
    last_message = messages[-1]
    
    # If there are no tool calls, we're done
    if not hasattr(last_message, "tool_calls") or not last_message.tool_calls:
        return "end"
    return "continue"


def call_model(state: AgentState):
    """Call the model."""
    llm = create_llm()
    tools = get_tools()
    llm_with_tools = llm.bind_tools(tools)
    
    messages = state["messages"]
    
    # Add system message if not present
    if not messages or not isinstance(messages[0], SystemMessage):
        messages = [SystemMessage(content=SYSTEM_PROMPT)] + messages
    
    response = llm_with_tools.invoke(messages)
    return {"messages": [response]}


def create_agent():
    """Create the LangGraph agent."""
    # Create the graph
    workflow = StateGraph(AgentState)
    
    # Add nodes
    workflow.add_node("agent", call_model)
    workflow.add_node("tools", ToolNode(get_tools()))
    
    # Set entry point
    workflow.set_entry_point("agent")
    
    # Add conditional edges
    workflow.add_conditional_edges(
        "agent",
        should_continue,
        {
            "continue": "tools",
            "end": END,
        }
    )
    
    # Add edge from tools back to agent
    workflow.add_edge("tools", "agent")
    
    # Compile the graph
    return workflow.compile()
```

---

## 10. src/ai_assistant/utils.py

```python
"""Utility functions for the AI assistant."""

from typing import Optional
import logging

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

logger = logging.getLogger(__name__)


def log_info(message: str) -> None:
    """Log an info message."""
    logger.info(message)


def log_error(message: str, exc_info: Optional[Exception] = None) -> None:
    """Log an error message."""
    logger.error(message, exc_info=exc_info)


def log_debug(message: str) -> None:
    """Log a debug message."""
    logger.debug(message)
```

---

## 11. tests/__init__.py

```python
"""Tests for the AI coding assistant."""
```

---

## 12. tests/test_agent.py

```python
"""Tests for the agent module."""

import pytest
from ai_assistant.agent import create_agent, AgentState
from ai_assistant.config import get_config


def test_create_agent():
    """Test agent creation."""
    agent = create_agent()
    assert agent is not None


@pytest.mark.asyncio
async def test_agent_invoke():
    """Test agent invocation."""
    # This test requires a valid API key
    try:
        config = get_config()
        if not config.openrouter_api_key:
            pytest.skip("No OpenRouter API key found")
        
        agent = create_agent()
        response = await agent.ainvoke({
            "messages": [("user", "Hello, how are you?")]
        })
        
        assert "messages" in response
        assert len(response["messages"]) > 0
        
    except Exception as e:
        pytest.skip(f"Test skipped due to: {e}")


def test_config():
    """Test configuration."""
    config = get_config()
    assert config is not None
    assert config.openrouter_model is not None
```

---

## 13. examples/basic_chat.py

```python
"""Basic chat example with the AI coding assistant."""

import asyncio
from ai_assistant.agent import create_agent


async def main():
    """Run a basic chat session."""
    print("AI Coding Assistant - Basic Chat")
    print("=" * 50)
    print("Type 'exit' or 'quit' to end the session\n")
    
    agent = create_agent()
    
    while True:
        # Get user input
        user_input = input("You: ").strip()
        
        # Check for exit commands
        if user_input.lower() in ["exit", "quit", "q"]:
            print("\nGoodbye! ğŸ‘‹")
            break
        
        if not user_input:
            continue
        
        try:
            # Invoke the agent
            response = await agent.ainvoke({
                "messages": [("user", user_input)]
            })
            
            # Print the response
            assistant_message = response["messages"][-1].content
            print(f"\nAssistant: {assistant_message}\n")
            
        except Exception as e:
            print(f"\nâŒ Error: {str(e)}\n")
            print("Please check your API key and internet connection.\n")


if __name__ == "__main__":
    asyncio.run(main())
```

---

## 14. examples/code_generation.py

```python
"""Code generation example."""

import asyncio
from ai_assistant.agent import create_agent


async def generate_code_example():
    """Example of using the agent for code generation."""
    print("AI Coding Assistant - Code Generation Example")
    print("=" * 50)
    
    agent = create_agent()
    
    # Example task
    task = """
    Write a Python function that:
    1. Takes a list of numbers as input
    2. Filters out even numbers
    3. Squares the remaining odd numbers
    4. Returns the sum of the squared odd numbers
    
    Include error handling and type hints.
    """
    
    print(f"Task:\n{task}\n")
    print("Generating code...\n")
    
    try:
        response = await agent.ainvoke({
            "messages": [("user", task)]
        })
        
        generated_code = response["messages"][-1].content
        print("Generated Code:")
        print("=" * 50)
        print(generated_code)
        print("=" * 50)
        
    except Exception as e:
        print(f"âŒ Error: {str(e)}")
        print("Please check your API key and configuration.")


if __name__ == "__main__":
    asyncio.run(generate_code_example())
```

---

## ìƒì„± ìˆœì„œ

Code ëª¨ë“œë¡œ ì „í™˜ í›„ ë‹¤ìŒ ìˆœì„œë¡œ íŒŒì¼ì„ ìƒì„±í•˜ë©´ ë©ë‹ˆë‹¤:

1. âœ… **ì„¤ì • íŒŒì¼ë“¤** (í”„ë¡œì íŠ¸ ê¸°ë°˜)
   - `pyproject.toml`
   - `.env.example`
   - `.gitignore`

2. âœ… **ì†ŒìŠ¤ ì½”ë“œ** (ì˜ì¡´ì„± ìˆœì„œ)
   - `src/ai_assistant/__init__.py`
   - `src/ai_assistant/config.py`
   - `src/ai_assistant/prompts.py`
   - `src/ai_assistant/utils.py`
   - `src/ai_assistant/tools.py`
   - `src/ai_assistant/agent.py`

3. âœ… **í…ŒìŠ¤íŠ¸**
   - `tests/__init__.py`
   - `tests/test_agent.py`

4. âœ… **ì˜ˆì œ**
   - `examples/basic_chat.py`
   - `examples/code_generation.py`

5. âœ… **ë¬¸ì„œ**
   - `README.md` (ì—…ë°ì´íŠ¸)

## í•„ìš”í•œ ì¶”ê°€ ì‘ì—…

íŒŒì¼ ìƒì„± í›„:

1. **UVë¡œ í”„ë¡œì íŠ¸ ì´ˆê¸°í™”**
   ```powershell
   uv venv
   .\.venv\Scripts\Activate.ps1
   uv pip install -e ".[dev]"
   ```

2. **í™˜ê²½ ë³€ìˆ˜ ì„¤ì •**
   ```powershell
   Copy-Item .env.example .env
   # .env íŒŒì¼ì— OpenRouter API í‚¤ ì…ë ¥
   ```

3. **í…ŒìŠ¤íŠ¸ ì‹¤í–‰**
   ```powershell
   pytest
   ```

4. **ì˜ˆì œ ì‹¤í–‰**
   ```powershell
   python examples/basic_chat.py